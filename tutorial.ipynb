{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MetalNeedle Tutorial\n",
    "First please follow the guidance in repo's [README](https://github.com/wenjunsun/dlsys-needle-m1/blob/main/README.md) to setup the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import needle as ndl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the tutorial successfully, you need to have a M1-enabled Mac, check if your computer satisfies the requirements with the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndl.m1().enabled()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple operations && automatic differentiation\n",
    "MetalNeedle satisfies all the basic tensor operations in other automatic differentiation tools like Pytorch, Tensorflow, etc. \n",
    "\n",
    "You can set the device argument to M1 to accelerate these operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ndl.Tensor(np.array([1, 2, 3]), device=ndl.m1(), requires_grad=True)\n",
    "b = ndl.Tensor(np.array([3, 2, 1]), device=ndl.m1(), requires_grad=True)\n",
    "c = ndl.Tensor(np.array([2, 2, 2]), device=ndl.m1(), requires_grad=True)\n",
    "d = ndl.exp((a + b) * c)\n",
    "e = ndl.relu(d)\n",
    "f = ndl.summation(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simple `backward` tensor method can automatically compute the gradient with backward propogation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(needle.Tensor([5961.9155 5961.9155 5961.9155]),\n",
       " needle.Tensor([5961.9155 5961.9155 5961.9155]),\n",
       " needle.Tensor([11923.831 11923.831 11923.831]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad, b.grad, c.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Multiplication\n",
    "Matrix multiplication is an important operation in Machine Learning area. With M1 GPU, you can easily achieve over 7x acceleration for the demo case below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "M, N, K = 1000, 1000, 1000\n",
    "A_m1 = ndl.Tensor(np.random.randn(M, K), device=ndl.m1())\n",
    "B_m1 = ndl.Tensor(np.random.randn(K, N), device=ndl.m1())\n",
    "A_cpu = ndl.Tensor(np.random.randn(M, K), device=ndl.cpu())\n",
    "B_cpu = ndl.Tensor(np.random.randn(K, N), device=ndl.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.3 ms ± 1.85 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit A_cpu @ B_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.79 ms ± 284 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit A_m1 @ B_m1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train ResNet on CIFAR10\n",
    "You can implement a ResNet in needle and train it on the CIFAR10 dataset. With M1 GPU acceleration, you can achieve 10x speedup training time. Currently the matrix multiplication is implemented in a naive way. We believe if it is implemented in a highly optimized way like Cublas, it can achieve competitive performance with CUDA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Acc: 0.3538, Loss: 1.80337234375, Time: 394.81s\n",
      "Epoch: 1, Acc: 0.46514, Loss: 1.48837484375, Time: 394.36s\n",
      "Epoch: 2, Acc: 0.51546, Loss: 1.3542328125, Time: 396.63s\n",
      "Epoch: 3, Acc: 0.5532, Loss: 1.2529396875, Time: 397.00s\n",
      "Epoch: 4, Acc: 0.58366, Loss: 1.1686440625, Time: 395.02s\n",
      "Epoch: 5, Acc: 0.612, Loss: 1.09461765625, Time: 393.30s\n",
      "Epoch: 6, Acc: 0.63522, Loss: 1.0276240625, Time: 396.00s\n",
      "Epoch: 7, Acc: 0.65828, Loss: 0.9641878125, Time: 422.36s\n",
      "Epoch: 8, Acc: 0.67964, Loss: 0.906412421875, Time: 1413.13s\n",
      "Epoch: 9, Acc: 0.70216, Loss: 0.85104984375, Time: 405.90s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4764, 1.683678515625)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"./apps\")\n",
    "from models import ResNet9\n",
    "from simple_training import train_cifar10, evaluate_cifar10\n",
    "\n",
    "device = ndl.m1()\n",
    "train_dataset = ndl.data.CIFAR10Dataset(\"data/cifar-10-batches-py\", train=True)\n",
    "train_dataloader = ndl.data.DataLoader(dataset=train_dataset,\n",
    "                                       batch_size=128,\n",
    "                                       shuffle=True,\n",
    "                                       device=device)\n",
    "test_dataset = ndl.data.CIFAR10Dataset(\"data/cifar-10-batches-py\", train=False)\n",
    "test_dataloader = ndl.data.DataLoader(dataset=test_dataset,\n",
    "                                       batch_size=128,\n",
    "                                       shuffle=True,\n",
    "                                       device=device)\n",
    "\n",
    "model = ResNet9(device=device, dtype=\"float32\")\n",
    "train_cifar10(model, train_dataloader, n_epochs=10, optimizer=ndl.optim.Adam,\n",
    "              lr=0.0005, weight_decay=0.001)\n",
    "evaluate_cifar10(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7cb1b9ae4d417fedf7f40a8eec98f7cfbd359e096bd857395a915f4609834ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
